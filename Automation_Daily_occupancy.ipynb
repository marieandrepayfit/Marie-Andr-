{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marieandrepayfit/Marie-Andr-/blob/main/Automation_Daily_occupancy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import json\n",
        "import os\n",
        "\n",
        "API_KEY = os.environ.get('DRIVE_API_KEY')\n",
        "\n",
        "# Configuration for authentication using the API key\n",
        "scope = [\n",
        "    \"https://spreadsheets.google.com/feeds\",\n",
        "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "    \"https://www.googleapis.com/auth/drive.file\",\n",
        "    \"https://www.googleapis.com/auth/drive\"\n",
        "]\n",
        "\n",
        "# Load the API key\n",
        "creds_dict = json.loads(API_KEY)\n",
        "\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "def calculate_occupancy_ranges_with_additional_metrics(df_sf, df_intercom, daily_working_hours=7.8):\n",
        "    \"\"\"\n",
        "    df_sf_V3 : https://payfit.eu.looker.com/explore/customer_success/cs_metrics?qid=X8P3JQXodONwAIGLIKuUeR&origin_space=2180&toggle=fil\n",
        "    df_intercom_V3 : https://payfit.eu.looker.com/explore/customer_success/cs_metrics?qid=tFJthLmYABynCLSIh2FQ7d&origin_space=2180&toggle=fil\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert event datetime to pandas datetime\n",
        "    df_sf['Clock out'] = pd.to_datetime(df_sf['1.1 - Events Event Date Second'], errors='coerce')\n",
        "    df_sf['Date day'] = pd.to_datetime(df_sf['1.1 - Events Event Date Date'], errors='coerce')\n",
        "    #-#\n",
        "    df_intercom['Clock out'] = pd.to_datetime(df_intercom['1.1 - Events Event Date Second'], errors='coerce')\n",
        "    df_intercom['Date day'] = pd.to_datetime(df_intercom['1.1 - Events Event Date Date'], errors='coerce')\n",
        "\n",
        "    # Define columns name\n",
        "    df_sf['Agent Email'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Payfiter e-mail']\n",
        "    df_sf['Service Level'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Service Level']\n",
        "    df_sf['Case ID'] = df_sf['1.2 - Cases Case ID']\n",
        "    df_sf['Date day'] = df_sf['1.1 - Events Event Date Date']\n",
        "    df_sf['Duration ci-co (s)'] = pd.to_numeric(df_sf['1.1 - Events Effective Time Spent Salesforce'], errors='coerce')\n",
        "    df_sf['Country'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Scope country code']\n",
        "    df_sf['Duration SF (s)'] = df_sf['Duration ci-co (s)']\n",
        "    df_sf['Duration Intercom (s)'] = 0\n",
        "    #-#\n",
        "    df_intercom['Agent Email'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Payfiter e-mail']\n",
        "    df_intercom['Service Level'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Service Level']\n",
        "    df_intercom['Case ID'] = df_intercom['1.2 - Cases Case ID']\n",
        "    df_intercom['Date day'] = df_intercom['1.1 - Events Event Date Date']\n",
        "    df_intercom['Duration ci-co (s)'] = pd.to_numeric(df_intercom['1.1 - Events Effective Time Spent Intercom'], errors='coerce')\n",
        "    df_intercom['Country'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Scope country code']\n",
        "    df_intercom['Duration SF (s)'] = 0\n",
        "    df_intercom['Duration Intercom (s)'] = df_intercom['Duration ci-co (s)']\n",
        "\n",
        "    # Merge the two DataFrames\n",
        "    merged_df = pd.merge(df_sf, df_intercom, on=['Agent Email', 'Service Level', 'Case ID', 'Date day', 'Duration ci-co (s)', 'Country', 'Clock out', 'Duration SF (s)', 'Duration Intercom (s)'], how='outer', indicator=True)\n",
        "    #print(merged_df.columns)\n",
        "\n",
        "    # Add measure for counting clock-outs at 8pm\n",
        "    merged_df['Clock Out Hour'] = merged_df['Clock out'].dt.hour\n",
        "    merged_df['Clock Out Minute'] = merged_df['Clock out'].dt.minute\n",
        "    merged_df['Clock Out at 20:00?'] = ((merged_df['Clock Out Hour'] == 20) & (merged_df['Clock Out Minute'] == 00))\n",
        "    # Add measure for counting ci-co during lunch\n",
        "    merged_df['Clock In'] = merged_df['Clock out'] - pd.to_timedelta(merged_df['Duration ci-co (s)'], unit='s')\n",
        "    merged_df['Clock In Hour'] = merged_df['Clock In'].dt.hour\n",
        "    merged_df['Clock In Minute'] = merged_df['Clock In'].dt.minute\n",
        "    merged_df['Clock In/Out lunch?'] = ((merged_df['Clock In Hour'] >= 11) & (merged_df['Clock In Hour'] <= 12) & (merged_df['Clock In Minute'] >= 30) & (merged_df['Clock Out Hour'] >= 13) & (merged_df['Clock Out Hour'] <= 14) & (merged_df['Clock Out Minute'] >= 30))\n",
        "\n",
        "    # Add a new column for the duration during lunch\n",
        "    merged_df['Duration during Lunch (s)'] = 0\n",
        "    # Filter rows where 'Clock In/Out lunch?' is True\n",
        "    lunch_filter = merged_df['Clock In/Out lunch?']\n",
        "    # Calculate the duration during lunch for rows where 'Clock In/Out lunch?' is True\n",
        "    merged_df.loc[lunch_filter, 'Duration during Lunch (s)'] = merged_df.loc[lunch_filter, 'Duration ci-co (s)']\n",
        "\n",
        "    # Exclude rows where the date of 'Clock In' is different from the date of 'Clock Out'\n",
        "    merged_df = merged_df[merged_df['Clock In'].dt.date == merged_df['Clock out'].dt.date]\n",
        "\n",
        "    # Flag aberrant values based on service level\n",
        "    merged_df['Aberrant Duration'] = np.where((merged_df['Service Level'] == 'CCR') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                      np.where((merged_df['Service Level'] == 'APS') & (merged_df['Duration ci-co (s)'] > 18000), 1, #5h\n",
        "                                               np.where((merged_df['Service Level'] == 'OBS') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                        np.where((merged_df['Service Level'] == 'CSM - Low touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                 np.where((merged_df['Service Level'] == 'CSM - Medium touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                          np.where((merged_df['Service Level'] == 'CSM - High touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                   np.where((merged_df['Service Level'] == 'Decla - DSN évènementielles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                            np.where((merged_df['Service Level'] == 'Declaration - DSN mensuelles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                     np.where((merged_df['Service Level'] == 'Decla - Investigation') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                              np.where((merged_df['Service Level'] == 'Decla - Paramétrage') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                       np.where((merged_df['Service Level'] == 'CSM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                np.where((merged_df['Service Level'] == 'CCM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                         np.where((merged_df['Service Level'] == 'Ext CCR') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                  np.where((merged_df['Service Level'] == 'Ext CSM/AM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                           np.where((merged_df['Service Level'] == 'Ext Evenementielles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                                                                                    np.where((merged_df['Service Level'] == 'Ext Mensuelles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                                                                                             np.where((merged_df['Service Level'] == 'Ext Paramétrages') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                      np.where((merged_df['Service Level'] == 'Ext OB') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                               np.where((merged_df['Service Level'] == 'Resolution - Absences') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                        np.where((merged_df['Service Level'] == 'Resolution - App & Donnees') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                 np.where((merged_df['Service Level'] == 'Resolution - Contrats') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                          np.where((merged_df['Service Level'] == 'Resolution - DSN Event') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                   np.where((merged_df['Service Level'] == 'Resolution - Encadrement') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                            np.where((merged_df['Service Level'] == 'Resolution - Mutuelle Prevoyance') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                     np.where((merged_df['Service Level'] == 'Resolution - Onboarding') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                              np.where((merged_df['Service Level'] == 'Resolution - Remuneration') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                       np.where((merged_df['Service Level'] == 'Resolution - URSSAF DGFIP') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                np.where((merged_df['Service Level'] == '\tResolution HUB') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                         np.where((merged_df['Service Level'] == 'Relationship') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                                  np.where((merged_df['Service Level'] == 'Expertise - Declaration') & (merged_df['Duration ci-co (s)'] > 12000), 1, #3,3h\n",
        "                                                                                                                                                                                                                                                                                                           np.where((merged_df['Service Level'] == 'Expertise - Payroll') & (merged_df['Duration ci-co (s)'] > 18000), 1, 0))))))))))))))))))))))))))))))) #5h\n",
        "\n",
        "\n",
        "    # Calculation Moving Medians (last 30 days)\n",
        "    # Convert 'Date day' in merged_df to datetime and sort\n",
        "    merged_df['Date day'] = pd.to_datetime(merged_df['Date day'], errors='coerce')\n",
        "    merged_df.sort_values(by=['Clock out', 'Agent Email'], inplace=True)\n",
        "    # Filter merged_df to calculate the median without clock out auto and aberrant duration\n",
        "    filtered_df = merged_df[(merged_df['Clock Out at 20:00?'] == False) &\n",
        "                            (merged_df['Aberrant Duration'] == False) &\n",
        "                            (merged_df['Duration ci-co (s)'] != 0)]\n",
        "    # Calculate the moving median per IC based on the last 30 days\n",
        "    filtered_df.loc[:, 'Median Duration on the last 30 days'] = filtered_df.groupby(['Agent Email'])['Duration ci-co (s)'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
        "    # Merge the DataFrames\n",
        "    merged_df = pd.merge(merged_df, filtered_df[['Agent Email', 'Date day', 'Clock out', 'Median Duration on the last 30 days']], how='left')\n",
        "    # Replace NaN values (when clock out auto or aberrant duration) with the previous median of the same Date day and Agent Email\n",
        "    merged_df.sort_values(by=['Clock out', 'Date day', 'Agent Email'], inplace=True)\n",
        "    merged_df['Median Duration on the last 30 days'] = merged_df.groupby(['Agent Email', 'Date day'])['Median Duration on the last 30 days'].fillna(method='ffill')\n",
        "\n",
        "    # Calculate daily totals per IC\n",
        "    daily_totals = merged_df.groupby(['Country', 'Service Level', 'Agent Email', 'Date day']).agg({\n",
        "        'Duration ci-co (s)': 'sum',\n",
        "        'Clock Out at 20:00?' : 'sum',\n",
        "        'Clock In/Out lunch?' : 'sum',\n",
        "        'Case ID': lambda x: x.tolist(),\n",
        "        'Aberrant Duration' : 'sum',\n",
        "        'Duration SF (s)' : 'sum',\n",
        "        'Duration Intercom (s)' :'sum',\n",
        "        'Median Duration on the last 30 days' : 'sum',\n",
        "        'Duration during Lunch (s)' : 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Replace 'Duration ci-co (s)' with median when 'Aberrant Duration' is True\n",
        "    merged_df['Duration ci-co Adjusted aberrant (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Aberrant Duration'] and row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'],axis=1)\n",
        "    # Replace 'Duration ci-co (s)' with median when 'Clock Out at 20:00?' is True\n",
        "    merged_df['Duration ci-co Adjusted co 20:00 (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Clock Out at 20:00?'] and row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'], axis=1)\n",
        "    # Combine both adjustments in a single metric\n",
        "    merged_df['Duration ci-co Adjusted (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Aberrant Duration'] or row['Clock Out at 20:00?']) and (row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'], axis=1)\n",
        "\n",
        "    # Add the calculation of the sum of Durations per day and per IC\n",
        "    sum_duration_aberrant_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted aberrant (s)'].sum().reset_index()\n",
        "    sum_duration_co20_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted co 20:00 (s)'].sum().reset_index()\n",
        "    sum_duration_adjusted_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted (s)'].sum().reset_index()\n",
        "\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_aberrant_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_co20_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_adjusted_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "\n",
        "    # Convert 'Duration ci-co' to numeric\n",
        "    daily_totals['Duration ci-co'] = pd.to_numeric(daily_totals['Duration ci-co (s)'], errors='coerce')\n",
        "\n",
        "    # Metrics\n",
        "    daily_totals['# Treated cases'] = daily_totals['Case ID'].apply(lambda x: len(set(x)))\n",
        "\n",
        "### PER SERVICE LEVEL ###\n",
        "    # Summarize per Service Level\n",
        "    occupancy_summary_service_level = daily_totals.groupby(['Date day', 'Country', 'Service Level']).agg({\n",
        "        '# Treated cases': 'sum',\n",
        "        'Case ID': lambda x: x.tolist(),\n",
        "        'Clock Out at 20:00?': 'sum',\n",
        "        'Clock In/Out lunch?': 'sum',\n",
        "        'Duration ci-co (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted aberrant (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted co 20:00 (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted (s)' : 'mean',\n",
        "        'Aberrant Duration' : 'sum',\n",
        "        'Duration SF (s)' : 'mean',\n",
        "        'Duration Intercom (s)' : 'mean',\n",
        "        'Duration during Lunch (s)' : 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Rename metrics if needed\n",
        "    occupancy_summary_service_level = occupancy_summary_service_level.rename(columns={'Clock Out at 20:00?': '# Clock Out at 20:00'})\n",
        "    occupancy_summary_service_level = occupancy_summary_service_level.rename(columns={'Clock In/Out lunch?': '# Clock In/Out lunch'})\n",
        "    occupancy_summary_service_level = occupancy_summary_service_level.rename(columns={'Aberrant Duration': '# Aberrant Duration'})\n",
        "\n",
        "    # Metrics\n",
        "    occupancy_summary_service_level['Avg Working time (h)'] = occupancy_summary_service_level['Duration ci-co (s)'] / 3600\n",
        "    occupancy_summary_service_level['% Occupancy'] = occupancy_summary_service_level['Avg Working time (h)'] / daily_working_hours * 100\n",
        "    occupancy_summary_service_level['Avg Working time Adjusted aberrant (h)'] = occupancy_summary_service_level['Duration ci-co Adjusted aberrant (s)'] / 3600\n",
        "    occupancy_summary_service_level['Avg Working time Adjusted co 20:00 (h)'] = occupancy_summary_service_level['Duration ci-co Adjusted co 20:00 (s)'] / 3600\n",
        "    occupancy_summary_service_level['Avg Working time Adjusted (h)'] = occupancy_summary_service_level['Duration ci-co Adjusted (s)'] / 3600\n",
        "    occupancy_summary_service_level['% Occupancy Adjusted'] = occupancy_summary_service_level['Avg Working time Adjusted (h)'] / daily_working_hours * 100\n",
        "    occupancy_summary_service_level['Avg ci-co SF (h)'] = occupancy_summary_service_level['Duration SF (s)'] / 3600\n",
        "    occupancy_summary_service_level['Avg ci-co Intercom (h)'] = occupancy_summary_service_level['Duration Intercom (s)'] / 3600\n",
        "    occupancy_summary_service_level['Avg ci-co during lunch (h)'] = occupancy_summary_service_level['Duration during Lunch (s)'] / 3600\n",
        "\n",
        "    # Reorder the columns to the specified order and sort by 'Service Level'\n",
        "    columns_order = ['Country', 'Date day', 'Service Level', '# Treated cases', '# Aberrant Duration', '# Clock Out at 20:00', '# Clock In/Out lunch', 'Avg ci-co SF (h)', 'Avg ci-co Intercom (h)', 'Avg ci-co during lunch (h)', 'Avg Working time (h)', 'Avg Working time Adjusted (h)', '% Occupancy', '% Occupancy Adjusted']\n",
        "    occupancy_summary_service_level = occupancy_summary_service_level[columns_order]\n",
        "\n",
        "    # Sort by 'Service Level'\n",
        "    occupancy_summary_service_level = occupancy_summary_service_level.sort_values(by=['Country', 'Service Level', 'Date day'], ascending=True)\n",
        "    occupancy_summary_service_level = occupancy_summary_service_level.set_index('% Occupancy Adjusted', drop=False)\n",
        "    return occupancy_summary_service_level\n",
        "\n",
        "### ... ###\n",
        "\n",
        "spreadsheet_name = '% occupancy'\n",
        "worksheet_title = 'Daily_slvl'\n",
        "worksheet_index_sf = 0  # l'index de la feuille pour df_sf\n",
        "worksheet_index_intercom = 1  # l'index de la feuille pour df_intercom\n",
        "\n",
        "# Open the spreadsheet\n",
        "worksheet = gc.open(spreadsheet_name)\n",
        "\n",
        "# Load data for df_sf\n",
        "worksheet_sf = worksheet.get_worksheet(worksheet_index_sf)\n",
        "data_sf = worksheet_sf.get_all_values()\n",
        "df_sf = pd.DataFrame(data_sf[1:], columns=data_sf[0])\n",
        "\n",
        "# Load data for df_intercom\n",
        "worksheet_intercom = worksheet.get_worksheet(worksheet_index_intercom)\n",
        "data_intercom = worksheet_intercom.get_all_values()\n",
        "df_intercom = pd.DataFrame(data_intercom[1:], columns=data_intercom[0])\n",
        "\n",
        "# Apply the function and obtain the summary\n",
        "occupancy_summary_with_metrics = calculate_occupancy_ranges_with_additional_metrics(df_sf, df_intercom)\n",
        "occupancy_summary_with_metrics = occupancy_summary_with_metrics.round(2)  # Arrondir à 2 décimales pour la table finale\n",
        "print(occupancy_summary_with_metrics)  # Afficher le résumé\n",
        "\n",
        "# Open the spreadsheet\n",
        "spreadsheet = gc.open(spreadsheet_name)\n",
        "\n",
        "try:\n",
        "    # Try to obtain the sheet by its title\n",
        "    worksheet = spreadsheet.worksheet(worksheet_title)\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    # If the sheet does not exist, create it\n",
        "    worksheet = spreadsheet.add_worksheet(title=worksheet_title, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame into a list of lists, including headers\n",
        "values = [occupancy_summary_with_metrics.columns.tolist()] + occupancy_summary_with_metrics.astype(str).values.tolist()\n",
        "\n",
        "# Update the sheet with the data, starting with cell A1\n",
        "worksheet.update('A1', values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDShslzixlck",
        "outputId": "1a929a1d-35fd-48e4-e960-c9da2b7ef1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-36b38e81c07a>:72: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
            "  merged_df = pd.merge(df_sf, df_intercom, on=['Agent Email', 'Service Level', 'Case ID', 'Date day', 'Duration ci-co (s)', 'Country', 'Clock out', 'Duration SF (s)', 'Duration Intercom (s)'], how='outer', indicator=True)\n",
            "<ipython-input-6-36b38e81c07a>:125: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df.loc[:, 'Median Duration on the last 30 days'] = filtered_df.groupby(['Agent Email'])['Duration ci-co (s)'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Country   Date day Service Level  # Treated cases  \\\n",
            "% Occupancy Adjusted                                                     \n",
            "50.199430                 ES 2024-02-19           CCR                6   \n",
            "42.140313                 ES 2024-02-20           CCR               14   \n",
            "44.145299                 ES 2024-02-21           CCR               13   \n",
            "25.336538                 ES 2024-02-22           CCR               13   \n",
            "44.962607                 ES 2024-02-23           CCR                8   \n",
            "...                      ...        ...           ...              ...   \n",
            "15.395299                 UK 2024-03-07           OBS                7   \n",
            "77.231125                 UK 2024-03-08           OBS                8   \n",
            "0.121083                  UK 2024-03-09           OBS                1   \n",
            "79.857550                 UK 2024-03-11           OBS               11   \n",
            "64.519231                 UK 2024-03-12           OBS               12   \n",
            "\n",
            "                      # Aberrant Duration  # Clock Out at 20:00  \\\n",
            "% Occupancy Adjusted                                              \n",
            "50.199430                               0                     0   \n",
            "42.140313                               0                     0   \n",
            "44.145299                               0                     0   \n",
            "25.336538                               1                     0   \n",
            "44.962607                               1                     1   \n",
            "...                                   ...                   ...   \n",
            "15.395299                               0                     0   \n",
            "77.231125                               1                     0   \n",
            "0.121083                                0                     0   \n",
            "79.857550                               1                     0   \n",
            "64.519231                               0                     0   \n",
            "\n",
            "                      # Clock In/Out lunch  Avg ci-co SF (h)  \\\n",
            "% Occupancy Adjusted                                           \n",
            "50.199430                                0              3.92   \n",
            "42.140313                                1              3.29   \n",
            "44.145299                                0              3.44   \n",
            "25.336538                                0              3.64   \n",
            "44.962607                                1              5.23   \n",
            "...                                    ...               ...   \n",
            "15.395299                                0              1.20   \n",
            "77.231125                                0             10.12   \n",
            "0.121083                                 0              0.01   \n",
            "79.857550                                0              8.99   \n",
            "64.519231                                0              5.03   \n",
            "\n",
            "                      Avg ci-co Intercom (h)  Avg ci-co during lunch (h)  \\\n",
            "% Occupancy Adjusted                                                       \n",
            "50.199430                                0.0                        0.00   \n",
            "42.140313                                0.0                        1.04   \n",
            "44.145299                                0.0                        0.00   \n",
            "25.336538                                0.0                        0.00   \n",
            "44.962607                                0.0                        1.02   \n",
            "...                                      ...                         ...   \n",
            "15.395299                                0.0                        0.00   \n",
            "77.231125                                0.0                        0.00   \n",
            "0.121083                                 0.0                        0.00   \n",
            "79.857550                                0.0                        0.00   \n",
            "64.519231                                0.0                        0.00   \n",
            "\n",
            "                      Avg Working time (h)  Avg Working time Adjusted (h)  \\\n",
            "% Occupancy Adjusted                                                        \n",
            "50.199430                             3.92                           3.92   \n",
            "42.140313                             3.29                           3.29   \n",
            "44.145299                             3.44                           3.44   \n",
            "25.336538                             3.64                           1.98   \n",
            "44.962607                             5.23                           3.51   \n",
            "...                                    ...                            ...   \n",
            "15.395299                             1.20                           1.20   \n",
            "77.231125                            10.12                           6.02   \n",
            "0.121083                              0.01                           0.01   \n",
            "79.857550                             8.99                           6.23   \n",
            "64.519231                             5.03                           5.03   \n",
            "\n",
            "                      % Occupancy  % Occupancy Adjusted  \n",
            "% Occupancy Adjusted                                     \n",
            "50.199430                   50.20                 50.20  \n",
            "42.140313                   42.14                 42.14  \n",
            "44.145299                   44.15                 44.15  \n",
            "25.336538                   46.62                 25.34  \n",
            "44.962607                   67.05                 44.96  \n",
            "...                           ...                   ...  \n",
            "15.395299                   15.40                 15.40  \n",
            "77.231125                  129.81                 77.23  \n",
            "0.121083                     0.12                  0.12  \n",
            "79.857550                  115.31                 79.86  \n",
            "64.519231                   64.52                 64.52  \n",
            "\n",
            "[368 rows x 14 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1bwVEpVquP4LCA_3hU5xuLlajE1PbwyXJf3c3MDuGeEM',\n",
              " 'updatedRange': \"'TEST MAN'!A1:N369\",\n",
              " 'updatedRows': 369,\n",
              " 'updatedColumns': 14,\n",
              " 'updatedCells': 5166}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_occupancy_ranges_with_additional_metrics(df_sf, df_intercom, daily_working_hours=7.8):\n",
        "    \"\"\"\n",
        "    df_sf_V3 : https://payfit.eu.looker.com/explore/customer_success/cs_metrics?qid=X8P3JQXodONwAIGLIKuUeR&origin_space=2180&toggle=fil\n",
        "    df_intercom_V3 : https://payfit.eu.looker.com/explore/customer_success/cs_metrics?qid=tFJthLmYABynCLSIh2FQ7d&origin_space=2180&toggle=fil\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert event datetime to pandas datetime\n",
        "    df_sf['Clock out'] = pd.to_datetime(df_sf['1.1 - Events Event Date Second'], errors='coerce')\n",
        "    df_sf['Date day'] = pd.to_datetime(df_sf['1.1 - Events Event Date Date'], errors='coerce')\n",
        "    #-#\n",
        "    df_intercom['Clock out'] = pd.to_datetime(df_intercom['1.1 - Events Event Date Second'], errors='coerce')\n",
        "    df_intercom['Date day'] = pd.to_datetime(df_intercom['1.1 - Events Event Date Date'], errors='coerce')\n",
        "\n",
        "    # Define columns name\n",
        "    df_sf['Agent Email'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Payfiter e-mail']\n",
        "    df_sf['Service Level'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Service Level']\n",
        "    df_sf['Case ID'] = df_sf['1.2 - Cases Case ID']\n",
        "    df_sf['Date day'] = df_sf['1.1 - Events Event Date Date']\n",
        "    df_sf['Duration ci-co (s)'] = pd.to_numeric(df_sf['1.1 - Events Effective Time Spent Salesforce'], errors='coerce')\n",
        "    df_sf['Country'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Scope country code']\n",
        "    df_sf['Duration SF (s)'] = df_sf['Duration ci-co (s)']\n",
        "    df_sf['Duration Intercom (s)'] = 0\n",
        "    #-#\n",
        "    df_intercom['Agent Email'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Payfiter e-mail']\n",
        "    df_intercom['Service Level'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Service Level']\n",
        "    df_intercom['Case ID'] = df_intercom['1.2 - Cases Case ID']\n",
        "    df_intercom['Date day'] = df_intercom['1.1 - Events Event Date Date']\n",
        "    df_intercom['Duration ci-co (s)'] = pd.to_numeric(df_intercom['1.1 - Events Effective Time Spent Intercom'], errors='coerce')\n",
        "    df_intercom['Country'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Scope country code']\n",
        "    df_intercom['Duration SF (s)'] = 0\n",
        "    df_intercom['Duration Intercom (s)'] = df_intercom['Duration ci-co (s)']\n",
        "\n",
        "    #print(df_intercom.dtypes)\n",
        "    #print(df_sf.dtypes)\n",
        "\n",
        "    # Merge the two DataFrames\n",
        "    merged_df = pd.merge(df_sf, df_intercom, on=['Agent Email', 'Service Level', 'Case ID', 'Date day', 'Duration ci-co (s)', 'Country', 'Clock out', 'Duration SF (s)', 'Duration Intercom (s)'], how='outer', indicator=True)\n",
        "    #print(merged_df.columns)\n",
        "\n",
        "    # Add measure for counting clock-outs at 8pm\n",
        "    merged_df['Clock Out Hour'] = merged_df['Clock out'].dt.hour\n",
        "    merged_df['Clock Out Minute'] = merged_df['Clock out'].dt.minute\n",
        "    merged_df['Clock Out at 20:00?'] = ((merged_df['Clock Out Hour'] == 20) & (merged_df['Clock Out Minute'] == 00))\n",
        "    # Add measure for counting ci-co during lunch\n",
        "    merged_df['Clock In'] = merged_df['Clock out'] - pd.to_timedelta(merged_df['Duration ci-co (s)'], unit='s')\n",
        "    merged_df['Clock In Hour'] = merged_df['Clock In'].dt.hour\n",
        "    merged_df['Clock In Minute'] = merged_df['Clock In'].dt.minute\n",
        "    merged_df['Clock In/Out lunch?'] = ((merged_df['Clock In Hour'] >= 11) & (merged_df['Clock In Hour'] <= 12) & (merged_df['Clock In Minute'] >= 30) & (merged_df['Clock Out Hour'] >= 13) & (merged_df['Clock Out Hour'] <= 14) & (merged_df['Clock Out Minute'] >= 30))\n",
        "\n",
        "    # Add a new column for the duration during lunch\n",
        "    merged_df['Duration during Lunch (s)'] = 0\n",
        "    # Filter rows where 'Clock In/Out lunch?' is True\n",
        "    lunch_filter = merged_df['Clock In/Out lunch?']\n",
        "    # Calculate the duration during lunch for rows where 'Clock In/Out lunch?' is True\n",
        "    merged_df.loc[lunch_filter, 'Duration during Lunch (s)'] = merged_df.loc[lunch_filter, 'Duration ci-co (s)']\n",
        "\n",
        "    # Exclude rows where the date of 'Clock In' is different from the date of 'Clock Out'\n",
        "    merged_df = merged_df[merged_df['Clock In'].dt.date == merged_df['Clock out'].dt.date]\n",
        "\n",
        "    # Flag aberrant values based on service level\n",
        "    merged_df['Aberrant Duration'] = np.where((merged_df['Service Level'] == 'CCR') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                      np.where((merged_df['Service Level'] == 'APS') & (merged_df['Duration ci-co (s)'] > 18000), 1, #5h\n",
        "                                               np.where((merged_df['Service Level'] == 'OBS') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                        np.where((merged_df['Service Level'] == 'CSM - Low touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                 np.where((merged_df['Service Level'] == 'CSM - Medium touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                          np.where((merged_df['Service Level'] == 'CSM - High touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                   np.where((merged_df['Service Level'] == 'Decla - DSN évènementielles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                            np.where((merged_df['Service Level'] == 'Declaration - DSN mensuelles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                     np.where((merged_df['Service Level'] == 'Decla - Investigation') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                              np.where((merged_df['Service Level'] == 'Decla - Paramétrage') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                       np.where((merged_df['Service Level'] == 'CSM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                np.where((merged_df['Service Level'] == 'CCM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                         np.where((merged_df['Service Level'] == 'Ext CCR') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                  np.where((merged_df['Service Level'] == 'Ext CSM/AM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                           np.where((merged_df['Service Level'] == 'Ext Evenementielles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                                                                                    np.where((merged_df['Service Level'] == 'Ext Mensuelles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                                                                                             np.where((merged_df['Service Level'] == 'Ext Paramétrages') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                      np.where((merged_df['Service Level'] == 'Ext OB') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                               np.where((merged_df['Service Level'] == 'Resolution - Absences') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                        np.where((merged_df['Service Level'] == 'Resolution - App & Donnees') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                 np.where((merged_df['Service Level'] == 'Resolution - Contrats') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                          np.where((merged_df['Service Level'] == 'Resolution - DSN Event') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                   np.where((merged_df['Service Level'] == 'Resolution - Encadrement') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                            np.where((merged_df['Service Level'] == 'Resolution - Mutuelle Prevoyance') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                     np.where((merged_df['Service Level'] == 'Resolution - Onboarding') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                              np.where((merged_df['Service Level'] == 'Resolution - Remuneration') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                       np.where((merged_df['Service Level'] == 'Resolution - URSSAF DGFIP') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                np.where((merged_df['Service Level'] == '\tResolution HUB') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                         np.where((merged_df['Service Level'] == 'Relationship') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                                  np.where((merged_df['Service Level'] == 'Expertise - Declaration') & (merged_df['Duration ci-co (s)'] > 12000), 1, #3,3h\n",
        "                                                                                                                                                                                                                                                                                                           np.where((merged_df['Service Level'] == 'Expertise - Payroll') & (merged_df['Duration ci-co (s)'] > 18000), 1, 0))))))))))))))))))))))))))))))) #5h\n",
        "\n",
        "\n",
        "    # Calculation Moving Medians (last 30 days)\n",
        "    # Convert 'Date day' in merged_df to datetime and sort\n",
        "    merged_df['Date day'] = pd.to_datetime(merged_df['Date day'], errors='coerce')\n",
        "    merged_df.sort_values(by=['Clock out', 'Agent Email'], inplace=True)\n",
        "    # Filter merged_df to calculate the median without clock out auto and aberrant duration\n",
        "    filtered_df = merged_df[(merged_df['Clock Out at 20:00?'] == False) &\n",
        "                            (merged_df['Aberrant Duration'] == False) &\n",
        "                            (merged_df['Duration ci-co (s)'] != 0)]\n",
        "    # Calculate the moving median per IC based on the last 30 days\n",
        "    filtered_df.loc[:, 'Median Duration on the last 30 days'] = filtered_df.groupby(['Agent Email'])['Duration ci-co (s)'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
        "    # Merge the DataFrames\n",
        "    merged_df = pd.merge(merged_df, filtered_df[['Agent Email', 'Date day', 'Clock out', 'Median Duration on the last 30 days']], how='left')\n",
        "    # Replace NaN values (when clock out auto or aberrant duration) with the previous median of the same Date day and Agent Email\n",
        "    merged_df.sort_values(by=['Clock out', 'Date day', 'Agent Email'], inplace=True)\n",
        "    merged_df['Median Duration on the last 30 days'] = merged_df.groupby(['Agent Email', 'Date day'])['Median Duration on the last 30 days'].fillna(method='ffill')\n",
        "\n",
        "    # Calculate daily totals per IC\n",
        "    daily_totals = merged_df.groupby(['Country', 'Service Level', 'Agent Email', 'Date day']).agg({\n",
        "        'Duration ci-co (s)': 'sum',\n",
        "        'Clock Out at 20:00?' : 'sum',\n",
        "        'Clock In/Out lunch?' : 'sum',\n",
        "        'Case ID': lambda x: x.tolist(),\n",
        "        'Aberrant Duration' : 'sum',\n",
        "        'Duration SF (s)' : 'sum',\n",
        "        'Duration Intercom (s)' :'sum',\n",
        "        'Median Duration on the last 30 days' : 'sum',\n",
        "        'Duration during Lunch (s)' : 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Replace 'Duration ci-co (s)' with median when 'Aberrant Duration' is True\n",
        "    merged_df['Duration ci-co Adjusted aberrant (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Aberrant Duration'] and row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'],axis=1)\n",
        "    # Replace 'Duration ci-co (s)' with median when 'Clock Out at 20:00?' is True\n",
        "    merged_df['Duration ci-co Adjusted co 20:00 (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Clock Out at 20:00?'] and row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'], axis=1)\n",
        "    # Combine both adjustments in a single metric\n",
        "    merged_df['Duration ci-co Adjusted (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Aberrant Duration'] or row['Clock Out at 20:00?']) and (row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'], axis=1)\n",
        "\n",
        "    # Add the calculation of the sum of Durations per day and per IC\n",
        "    sum_duration_aberrant_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted aberrant (s)'].sum().reset_index()\n",
        "    sum_duration_co20_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted co 20:00 (s)'].sum().reset_index()\n",
        "    sum_duration_adjusted_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted (s)'].sum().reset_index()\n",
        "\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_aberrant_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_co20_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_adjusted_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    #daily_totals = pd.merge(daily_totals, sum_duration_ci_co_lunch, on=['Date day', 'Agent Email'], how='left')\n",
        "\n",
        "    # Convert 'Duration ci-co' to numeric\n",
        "    daily_totals['Duration ci-co'] = pd.to_numeric(daily_totals['Duration ci-co (s)'], errors='coerce')\n",
        "\n",
        "    # Metrics\n",
        "    daily_totals['# Treated cases'] = daily_totals['Case ID'].apply(lambda x: len(set(x)))\n",
        "\n",
        "### PER COUNTRY ###\n",
        "    # Summarize per country\n",
        "    occupancy_summary_country = daily_totals.groupby(['Date day', 'Country']).agg({\n",
        "        '# Treated cases': 'sum',\n",
        "        'Case ID': lambda x: x.tolist(),\n",
        "        'Clock Out at 20:00?': 'sum',\n",
        "        'Clock In/Out lunch?': 'sum',\n",
        "        'Duration ci-co (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted aberrant (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted co 20:00 (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted (s)' : 'mean',\n",
        "        'Aberrant Duration' : 'sum',\n",
        "        'Duration SF (s)' : 'mean',\n",
        "        'Duration Intercom (s)' : 'mean',\n",
        "        'Duration during Lunch (s)' : 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Rename metrics if needed\n",
        "    occupancy_summary_country = occupancy_summary_country.rename(columns={'Clock Out at 20:00?': '# Clock Out at 20:00'})\n",
        "    occupancy_summary_country = occupancy_summary_country.rename(columns={'Clock In/Out lunch?': '# Clock In/Out lunch'})\n",
        "    occupancy_summary_country = occupancy_summary_country.rename(columns={'Aberrant Duration': '# Aberrant Duration'})\n",
        "\n",
        "    # Metrics\n",
        "    occupancy_summary_country['Avg Working time (h)'] = occupancy_summary_country['Duration ci-co (s)'] / 3600\n",
        "    occupancy_summary_country['% Occupancy'] = occupancy_summary_country['Avg Working time (h)'] / daily_working_hours * 100\n",
        "    occupancy_summary_country['Avg Working time Adjusted aberrant (h)'] = occupancy_summary_country['Duration ci-co Adjusted aberrant (s)'] / 3600\n",
        "    occupancy_summary_country['Avg Working time Adjusted co 20:00 (h)'] = occupancy_summary_country['Duration ci-co Adjusted co 20:00 (s)'] / 3600\n",
        "    occupancy_summary_country['Avg Working time Adjusted (h)'] = occupancy_summary_country['Duration ci-co Adjusted (s)'] / 3600\n",
        "    occupancy_summary_country['% Occupancy Adjusted'] = occupancy_summary_country['Avg Working time Adjusted (h)'] / daily_working_hours * 100\n",
        "    occupancy_summary_country['Avg ci-co SF (h)'] = occupancy_summary_country['Duration SF (s)'] / 3600\n",
        "    occupancy_summary_country['Avg ci-co Intercom (h)'] = occupancy_summary_country['Duration Intercom (s)'] / 3600\n",
        "    occupancy_summary_country['Avg ci-co during lunch (h)'] = occupancy_summary_country['Duration during Lunch (s)'] / 3600\n",
        "\n",
        "    # Reorder the columns to the specified order and sort by 'Service Level'\n",
        "    columns_order = ['Country', 'Date day', '# Treated cases', '# Aberrant Duration', '# Clock Out at 20:00', '# Clock In/Out lunch', 'Avg ci-co SF (h)', 'Avg ci-co Intercom (h)', 'Avg ci-co during lunch (h)', 'Avg Working time (h)', 'Avg Working time Adjusted (h)', '% Occupancy', '% Occupancy Adjusted']\n",
        "    occupancy_summary_country = occupancy_summary_country[columns_order]\n",
        "\n",
        "    # Sort by 'Country', 'Service Level', 'Date day'\n",
        "    occupancy_summary_country = occupancy_summary_country.sort_values(by=['Country', 'Date day'], ascending=True)\n",
        "    occupancy_summary_country = occupancy_summary_country.set_index('% Occupancy Adjusted', drop=False)\n",
        "    return occupancy_summary_country\n",
        "### ... ###\n",
        "\n",
        "spreadsheet_name = '% occupancy'\n",
        "worksheet_title = 'Daily_country'\n",
        "worksheet_index_sf = 0  # l'index de la feuille pour df_sf\n",
        "worksheet_index_intercom = 1  # l'index de la feuille pour df_intercom\n",
        "\n",
        "# Open the spreadsheet\n",
        "worksheet = gc.open(spreadsheet_name)\n",
        "\n",
        "# Load data for df_sf\n",
        "worksheet_sf = worksheet.get_worksheet(worksheet_index_sf)\n",
        "data_sf = worksheet_sf.get_all_values()\n",
        "df_sf = pd.DataFrame(data_sf[1:], columns=data_sf[0])\n",
        "\n",
        "# Load data for df_intercom\n",
        "worksheet_intercom = worksheet.get_worksheet(worksheet_index_intercom)\n",
        "data_intercom = worksheet_intercom.get_all_values()\n",
        "df_intercom = pd.DataFrame(data_intercom[1:], columns=data_intercom[0])\n",
        "\n",
        "# Apply the function and obtain the summary\n",
        "occupancy_summary_with_metrics = calculate_occupancy_ranges_with_additional_metrics(df_sf, df_intercom)\n",
        "occupancy_summary_with_metrics = occupancy_summary_with_metrics.round(2)  # Arrondir à 2 décimales pour la table finale\n",
        "print(occupancy_summary_with_metrics)  # Afficher le résumé\n",
        "\n",
        "# Open the spreadsheet\n",
        "spreadsheet = gc.open(spreadsheet_name)\n",
        "\n",
        "try:\n",
        "    # Try to obtain the sheet by its title\n",
        "    worksheet = spreadsheet.worksheet(worksheet_title)\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    # If the sheet does not exist, create it\n",
        "    worksheet = spreadsheet.add_worksheet(title=worksheet_title, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame into a list of lists, including headers\n",
        "values = [occupancy_summary_with_metrics.columns.tolist()] + occupancy_summary_with_metrics.astype(str).values.tolist()\n",
        "\n",
        "# Update the sheet with the data, starting with cell A1\n",
        "worksheet.update('A1', values)"
      ],
      "metadata": {
        "id": "yd7vcwjkRKqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_occupancy_ranges_with_additional_metrics(df_sf, df_intercom, daily_working_hours=7.8):\n",
        "    \"\"\"\n",
        "    df_sf_V3 : https://payfit.eu.looker.com/explore/customer_success/cs_metrics?qid=X8P3JQXodONwAIGLIKuUeR&origin_space=2180&toggle=fil\n",
        "    df_intercom_V3 : https://payfit.eu.looker.com/explore/customer_success/cs_metrics?qid=tFJthLmYABynCLSIh2FQ7d&origin_space=2180&toggle=fil\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert event datetime to pandas datetime\n",
        "    df_sf['Clock out'] = pd.to_datetime(df_sf['1.1 - Events Event Date Second'], errors='coerce')\n",
        "    df_sf['Date day'] = pd.to_datetime(df_sf['1.1 - Events Event Date Date'], errors='coerce')\n",
        "    #-#\n",
        "    df_intercom['Clock out'] = pd.to_datetime(df_intercom['1.1 - Events Event Date Second'], errors='coerce')\n",
        "    df_intercom['Date day'] = pd.to_datetime(df_intercom['1.1 - Events Event Date Date'], errors='coerce')\n",
        "\n",
        "    # Define columns name\n",
        "    df_sf['Agent Email'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Payfiter e-mail']\n",
        "    df_sf['Service Level'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Service Level']\n",
        "    df_sf['Case ID'] = df_sf['1.2 - Cases Case ID']\n",
        "    df_sf['Date day'] = df_sf['1.1 - Events Event Date Date']\n",
        "    df_sf['Duration ci-co (s)'] = pd.to_numeric(df_sf['1.1 - Events Effective Time Spent Salesforce'], errors='coerce')\n",
        "    df_sf['Country'] = df_sf['2.2 - Payfiter - Event Modifier - Dynamic Scope country code']\n",
        "    df_sf['Duration SF (s)'] = df_sf['Duration ci-co (s)']\n",
        "    df_sf['Duration Intercom (s)'] = 0\n",
        "    #-#\n",
        "    df_intercom['Agent Email'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Payfiter e-mail']\n",
        "    df_intercom['Service Level'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Service Level']\n",
        "    df_intercom['Case ID'] = df_intercom['1.2 - Cases Case ID']\n",
        "    df_intercom['Date day'] = df_intercom['1.1 - Events Event Date Date']\n",
        "    df_intercom['Duration ci-co (s)'] = pd.to_numeric(df_intercom['1.1 - Events Effective Time Spent Intercom'], errors='coerce')\n",
        "    df_intercom['Country'] = df_intercom['2.1 - Payfiter - Event Owner - Dynamic Scope country code']\n",
        "    df_intercom['Duration SF (s)'] = 0\n",
        "    df_intercom['Duration Intercom (s)'] = df_intercom['Duration ci-co (s)']\n",
        "\n",
        "    # Merge the two DataFrames\n",
        "    merged_df = pd.merge(df_sf, df_intercom, on=['Agent Email', 'Service Level', 'Case ID', 'Date day', 'Duration ci-co (s)', 'Country', 'Clock out', 'Duration SF (s)', 'Duration Intercom (s)'], how='outer', indicator=True)\n",
        "    #print(merged_df.columns)\n",
        "\n",
        "    # Add measure for counting clock-outs at 8pm\n",
        "    merged_df['Clock Out Hour'] = merged_df['Clock out'].dt.hour\n",
        "    merged_df['Clock Out Minute'] = merged_df['Clock out'].dt.minute\n",
        "    merged_df['Clock Out at 20:00?'] = ((merged_df['Clock Out Hour'] == 20) & (merged_df['Clock Out Minute'] == 00))\n",
        "    # Add measure for counting ci-co during lunch\n",
        "    merged_df['Clock In'] = merged_df['Clock out'] - pd.to_timedelta(merged_df['Duration ci-co (s)'], unit='s')\n",
        "    merged_df['Clock In Hour'] = merged_df['Clock In'].dt.hour\n",
        "    merged_df['Clock In Minute'] = merged_df['Clock In'].dt.minute\n",
        "    merged_df['Clock In/Out lunch?'] = ((merged_df['Clock In Hour'] >= 11) & (merged_df['Clock In Hour'] <= 12) & (merged_df['Clock In Minute'] >= 30) & (merged_df['Clock Out Hour'] >= 13) & (merged_df['Clock Out Hour'] <= 14) & (merged_df['Clock Out Minute'] >= 30))\n",
        "\n",
        "    # Add a new column for the duration during lunch\n",
        "    merged_df['Duration during Lunch (s)'] = 0\n",
        "    # Filter rows where 'Clock In/Out lunch?' is True\n",
        "    lunch_filter = merged_df['Clock In/Out lunch?']\n",
        "    # Calculate the duration during lunch for rows where 'Clock In/Out lunch?' is True\n",
        "    merged_df.loc[lunch_filter, 'Duration during Lunch (s)'] = merged_df.loc[lunch_filter, 'Duration ci-co (s)']\n",
        "\n",
        "    # Exclude rows where the date of 'Clock In' is different from the date of 'Clock Out'\n",
        "    merged_df = merged_df[merged_df['Clock In'].dt.date == merged_df['Clock out'].dt.date]\n",
        "\n",
        "    # Flag aberrant values based on service level\n",
        "    merged_df['Aberrant Duration'] = np.where((merged_df['Service Level'] == 'CCR') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                      np.where((merged_df['Service Level'] == 'APS') & (merged_df['Duration ci-co (s)'] > 18000), 1, #5h\n",
        "                                               np.where((merged_df['Service Level'] == 'OBS') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                        np.where((merged_df['Service Level'] == 'CSM - Low touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                 np.where((merged_df['Service Level'] == 'CSM - Medium touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                          np.where((merged_df['Service Level'] == 'CSM - High touch') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                   np.where((merged_df['Service Level'] == 'Decla - DSN évènementielles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                            np.where((merged_df['Service Level'] == 'Declaration - DSN mensuelles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                     np.where((merged_df['Service Level'] == 'Decla - Investigation') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                              np.where((merged_df['Service Level'] == 'Decla - Paramétrage') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                       np.where((merged_df['Service Level'] == 'CSM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                np.where((merged_df['Service Level'] == 'CCM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                         np.where((merged_df['Service Level'] == 'Ext CCR') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                  np.where((merged_df['Service Level'] == 'Ext CSM/AM') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                           np.where((merged_df['Service Level'] == 'Ext Evenementielles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                                                                                    np.where((merged_df['Service Level'] == 'Ext Mensuelles') & (merged_df['Duration ci-co (s)'] > 12600), 1, #3,5h\n",
        "                                                                                                                                                                             np.where((merged_df['Service Level'] == 'Ext Paramétrages') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                      np.where((merged_df['Service Level'] == 'Ext OB') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                               np.where((merged_df['Service Level'] == 'Resolution - Absences') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                        np.where((merged_df['Service Level'] == 'Resolution - App & Donnees') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                 np.where((merged_df['Service Level'] == 'Resolution - Contrats') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                          np.where((merged_df['Service Level'] == 'Resolution - DSN Event') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                   np.where((merged_df['Service Level'] == 'Resolution - Encadrement') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                            np.where((merged_df['Service Level'] == 'Resolution - Mutuelle Prevoyance') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                     np.where((merged_df['Service Level'] == 'Resolution - Onboarding') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                              np.where((merged_df['Service Level'] == 'Resolution - Remuneration') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                       np.where((merged_df['Service Level'] == 'Resolution - URSSAF DGFIP') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                np.where((merged_df['Service Level'] == '\tResolution HUB') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                         np.where((merged_df['Service Level'] == 'Relationship') & (merged_df['Duration ci-co (s)'] > 9000), 1, #2,5h\n",
        "                                                                                                                                                                                                                                                                                                  np.where((merged_df['Service Level'] == 'Expertise - Declaration') & (merged_df['Duration ci-co (s)'] > 12000), 1, #3,3h\n",
        "                                                                                                                                                                                                                                                                                                           np.where((merged_df['Service Level'] == 'Expertise - Payroll') & (merged_df['Duration ci-co (s)'] > 18000), 1, 0))))))))))))))))))))))))))))))) #5h\n",
        "\n",
        "\n",
        "    # Calculation Moving Medians (last 30 days)\n",
        "    # Convert 'Date day' in merged_df to datetime and sort\n",
        "    merged_df['Date day'] = pd.to_datetime(merged_df['Date day'], errors='coerce')\n",
        "    merged_df.sort_values(by=['Clock out', 'Agent Email'], inplace=True)\n",
        "    # Filter merged_df to calculate the median without clock out auto and aberrant duration\n",
        "    filtered_df = merged_df[(merged_df['Clock Out at 20:00?'] == False) &\n",
        "                            (merged_df['Aberrant Duration'] == False) &\n",
        "                            (merged_df['Duration ci-co (s)'] != 0)]\n",
        "    # Calculate the moving median per IC based on the last 30 days\n",
        "    filtered_df.loc[:, 'Median Duration on the last 30 days'] = filtered_df.groupby(['Agent Email'])['Duration ci-co (s)'].transform(lambda x: x.rolling(window=30, min_periods=1).median())\n",
        "    # Merge the DataFrames\n",
        "    merged_df = pd.merge(merged_df, filtered_df[['Agent Email', 'Date day', 'Clock out', 'Median Duration on the last 30 days']], how='left')\n",
        "    # Replace NaN values (when clock out auto or aberrant duration) with the previous median of the same Date day and Agent Email\n",
        "    merged_df.sort_values(by=['Clock out', 'Date day', 'Agent Email'], inplace=True)\n",
        "    merged_df['Median Duration on the last 30 days'] = merged_df.groupby(['Agent Email', 'Date day'])['Median Duration on the last 30 days'].fillna(method='ffill')\n",
        "\n",
        "    # Calculate daily totals per IC\n",
        "    daily_totals = merged_df.groupby(['Country', 'Service Level', 'Agent Email', 'Date day']).agg({\n",
        "        'Duration ci-co (s)': 'sum',\n",
        "        'Clock Out at 20:00?' : 'sum',\n",
        "        'Clock In/Out lunch?' : 'sum',\n",
        "        'Case ID': lambda x: x.tolist(),\n",
        "        'Aberrant Duration' : 'sum',\n",
        "        'Duration SF (s)' : 'sum',\n",
        "        'Duration Intercom (s)' :'sum',\n",
        "        'Median Duration on the last 30 days' : 'sum',\n",
        "        'Duration during Lunch (s)' : 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Replace 'Duration ci-co (s)' with median when 'Aberrant Duration' is True\n",
        "    merged_df['Duration ci-co Adjusted aberrant (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Aberrant Duration'] and row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'],axis=1)\n",
        "    # Replace 'Duration ci-co (s)' with median when 'Clock Out at 20:00?' is True\n",
        "    merged_df['Duration ci-co Adjusted co 20:00 (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Clock Out at 20:00?'] and row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'], axis=1)\n",
        "    # Combine both adjustments in a single metric\n",
        "    merged_df['Duration ci-co Adjusted (s)'] = merged_df.apply(lambda row: row['Median Duration on the last 30 days'] if (row['Aberrant Duration'] or row['Clock Out at 20:00?']) and (row['Median Duration on the last 30 days'] < row['Duration ci-co (s)']) else row['Duration ci-co (s)'], axis=1)\n",
        "\n",
        "    # Add the calculation of the sum of Durations per day and per IC\n",
        "    sum_duration_aberrant_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted aberrant (s)'].sum().reset_index()\n",
        "    sum_duration_co20_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted co 20:00 (s)'].sum().reset_index()\n",
        "    sum_duration_adjusted_per_day_ic = merged_df.groupby(['Date day', 'Agent Email'])['Duration ci-co Adjusted (s)'].sum().reset_index()\n",
        "\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_aberrant_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_co20_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    daily_totals = pd.merge(daily_totals, sum_duration_adjusted_per_day_ic, on=['Date day', 'Agent Email'], how='left')\n",
        "    #daily_totals = pd.merge(daily_totals, sum_duration_ci_co_lunch, on=['Date day', 'Agent Email'], how='left')\n",
        "\n",
        "    # Convert 'Duration ci-co' to numeric\n",
        "    daily_totals['Duration ci-co'] = pd.to_numeric(daily_totals['Duration ci-co (s)'], errors='coerce')\n",
        "\n",
        "    # Metrics\n",
        "    daily_totals['# Treated cases'] = daily_totals['Case ID'].apply(lambda x: len(set(x)))\n",
        "\n",
        "### PER IC ###\n",
        "    # Summarize per IC\n",
        "    occupancy_summary_IC = daily_totals.groupby(['Date day', 'Country','Service Level', 'Agent Email']).agg({\n",
        "        '# Treated cases': 'sum',\n",
        "        'Case ID': lambda x: x.tolist(),\n",
        "        'Clock Out at 20:00?': 'sum',\n",
        "        'Clock In/Out lunch?': 'sum',\n",
        "        'Duration ci-co (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted aberrant (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted co 20:00 (s)' : 'mean',\n",
        "        'Duration ci-co Adjusted (s)' : 'mean',\n",
        "        'Aberrant Duration' : 'sum',\n",
        "        'Duration SF (s)' : 'mean',\n",
        "        'Duration Intercom (s)' : 'mean',\n",
        "        'Duration during Lunch (s)' : 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    # Rename metrics if needed\n",
        "    occupancy_summary_IC = occupancy_summary_IC.rename(columns={'Clock Out at 20:00?': '# Clock Out at 20:00'})\n",
        "    occupancy_summary_IC = occupancy_summary_IC.rename(columns={'Clock In/Out lunch?': '# Clock In/Out lunch'})\n",
        "    occupancy_summary_IC = occupancy_summary_IC.rename(columns={'Aberrant Duration': '# Aberrant Duration'})\n",
        "\n",
        "    # Metrics\n",
        "    occupancy_summary_IC['Avg Working time (h)'] = occupancy_summary_IC['Duration ci-co (s)'] / 3600\n",
        "    occupancy_summary_IC['% Occupancy'] = occupancy_summary_IC['Avg Working time (h)'] / daily_working_hours * 100\n",
        "    occupancy_summary_IC['Avg Working time Adjusted aberrant (h)'] = occupancy_summary_IC['Duration ci-co Adjusted aberrant (s)'] / 3600\n",
        "    occupancy_summary_IC['Avg Working time Adjusted co 20:00 (h)'] = occupancy_summary_IC['Duration ci-co Adjusted co 20:00 (s)'] / 3600\n",
        "    occupancy_summary_IC['Avg Working time Adjusted (h)'] = occupancy_summary_IC['Duration ci-co Adjusted (s)'] / 3600\n",
        "    occupancy_summary_IC['% Occupancy Adjusted'] = occupancy_summary_IC['Avg Working time Adjusted (h)'] / daily_working_hours * 100\n",
        "    occupancy_summary_IC['Avg ci-co SF (h)'] = occupancy_summary_IC['Duration SF (s)'] / 3600\n",
        "    occupancy_summary_IC['Avg ci-co Intercom (h)'] = occupancy_summary_IC['Duration Intercom (s)'] / 3600\n",
        "    occupancy_summary_IC['Avg ci-co during lunch (h)'] = occupancy_summary_IC['Duration during Lunch (s)'] / 3600\n",
        "\n",
        "    # Reorder the columns to the specified order and sort by 'Service Level'\n",
        "    columns_order = ['Country', 'Date day', 'Service Level', 'Agent Email', '# Treated cases', '# Aberrant Duration', '# Clock Out at 20:00', '# Clock In/Out lunch', 'Avg ci-co SF (h)', 'Avg ci-co Intercom (h)', 'Avg ci-co during lunch (h)', 'Avg Working time (h)', 'Avg Working time Adjusted (h)', '% Occupancy', '% Occupancy Adjusted']\n",
        "    occupancy_summary_IC = occupancy_summary_IC[columns_order]\n",
        "\n",
        "    # Sort by 'Country', 'Service Level', 'Date day'\n",
        "    occupancy_summary_IC = occupancy_summary_IC.sort_values(by=['Country', 'Service Level', 'Date day'], ascending=True)\n",
        "    occupancy_summary_IC = occupancy_summary_IC.set_index('% Occupancy Adjusted', drop=False)\n",
        "    return occupancy_summary_IC\n",
        "### ... ###\n",
        "\n",
        "spreadsheet_name = '% occupancy'\n",
        "worksheet_title = 'Daily_IC'\n",
        "worksheet_index_sf = 0  # l'index de la feuille pour df_sf\n",
        "worksheet_index_intercom = 1  # l'index de la feuille pour df_intercom\n",
        "\n",
        "# Open the spreadsheet\n",
        "worksheet = gc.open(spreadsheet_name)\n",
        "\n",
        "# Load data for df_sf\n",
        "worksheet_sf = worksheet.get_worksheet(worksheet_index_sf)\n",
        "data_sf = worksheet_sf.get_all_values()\n",
        "df_sf = pd.DataFrame(data_sf[1:], columns=data_sf[0])\n",
        "\n",
        "# Load data for df_intercom\n",
        "worksheet_intercom = worksheet.get_worksheet(worksheet_index_intercom)\n",
        "data_intercom = worksheet_intercom.get_all_values()\n",
        "df_intercom = pd.DataFrame(data_intercom[1:], columns=data_intercom[0])\n",
        "\n",
        "# Apply the function and obtain the summary\n",
        "occupancy_summary_with_metrics = calculate_occupancy_ranges_with_additional_metrics(df_sf, df_intercom)\n",
        "occupancy_summary_with_metrics = occupancy_summary_with_metrics.round(2)  # Arrondir à 2 décimales pour la table finale\n",
        "print(occupancy_summary_with_metrics)  # Afficher le résumé\n",
        "\n",
        "# Open the spreadsheet\n",
        "spreadsheet = gc.open(spreadsheet_name)\n",
        "\n",
        "try:\n",
        "    # Try to obtain the sheet by its title\n",
        "    worksheet = spreadsheet.worksheet(worksheet_title)\n",
        "except gspread.exceptions.WorksheetNotFound:\n",
        "    # If the sheet does not exist, create it\n",
        "    worksheet = spreadsheet.add_worksheet(title=worksheet_title, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame into a list of lists, including headers\n",
        "values = [occupancy_summary_with_metrics.columns.tolist()] + occupancy_summary_with_metrics.astype(str).values.tolist()\n",
        "\n",
        "# Update the sheet with the data, starting with cell A1\n",
        "worksheet.update('A1', values)"
      ],
      "metadata": {
        "id": "FGvYK1f_Qi-K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}